{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df65e62f",
   "metadata": {},
   "source": [
    "# US Recession Prediction Model\n",
    "\n",
    "This notebook will make ananalysis of economic indicators from multiple countries\n",
    "\n",
    "**Approach** Binary Classification since if A recession will occur is a y or n outcome.\n",
    "\n",
    "**Features**\n",
    "- Yield curve spread (10Y - 3M)\n",
    "- GDP Growth rates\n",
    "- Intrest rate levels\n",
    "- Trade balances\n",
    "- Lagged features that predict recessions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96890468",
   "metadata": {},
   "source": [
    "# 1.Data Loading\n",
    "\n",
    "Country and variables map for parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ec656cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# country and variable mapping to make it easier to upload data\n",
    "country_map = {\n",
    "    \"CH\": \"ch\",\n",
    "    \"EU\": \"eu\",\n",
    "    \"JP\": \"jp\",\n",
    "    \"KR\": \"kr\",\n",
    "    \"UK\": \"uk\",\n",
    "    \"US\": \"us\"\n",
    "}\n",
    "\n",
    "variable_map = {\n",
    "    \"TB3MS\": \"3m\",\n",
    "    \"T10YR\": \"10y\",\n",
    "    \"CPI\": \"cpi\",\n",
    "    \"GDP\": \"gdp\",\n",
    "    \"EXP\": \"exp\",\n",
    "    \"IMP\": \"imp\",\n",
    "    \"REC\": \"rec\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b95124b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONALITY: Correctly parses dates in data\n",
    "def smart_parse_dates(series):\n",
    "  import pandas as pd\n",
    "\n",
    "  # Excel serial date handling\n",
    "  if pd.api.types.is_numeric_dtype(series):\n",
    "    return pd.to_datetime(series, unit=\"D\", origin=\"1899-12-30\", errors=\"coerce\")\n",
    "\n",
    "  # Convert to string and strip spaces\n",
    "  series = series.astype(str).str.strip()\n",
    "\n",
    "  # Try common formats\n",
    "  formats = [\n",
    "    \"%Y-%m-%d\",\n",
    "    \"%Y-%m\",\n",
    "    \"%Y/%m/%d\",\n",
    "    \"%Y/%m\",\n",
    "    \"%b %Y\",\n",
    "    \"%Y\"\n",
    "  ]\n",
    "\n",
    "  for fmt in formats:\n",
    "    try:\n",
    "      parsed = pd.to_datetime(series, format=fmt)\n",
    "      # If at least some rows parsed, assume correct format\n",
    "      if parsed.notna().sum() > 0:\n",
    "        return parsed\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "  # Handle formats like \"2024M01\"\n",
    "  try:\n",
    "    series_mod = series.str.replace(\"M\", \"-\", regex=False)\n",
    "    parsed = pd.to_datetime(series_mod, format=\"%Y-%m\")\n",
    "    return parsed\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "  # Fallback\n",
    "  return pd.to_datetime(series, errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc091e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONALITY: Loads data using specific path\n",
    "from pathlib import Path\n",
    "from typing import Union, Optional\n",
    "import pandas as pd\n",
    "\n",
    "def load_series_auto(path: Union[str, Path], date_col: Optional[str] = None):\n",
    "  path = Path(path)\n",
    "  folder = path.parent.name\n",
    "  file = path.name\n",
    "\n",
    "  # detect country\n",
    "  ccode = file[:2].upper()\n",
    "  if ccode not in country_map:\n",
    "    raise ValueError(f\"Unknown country code in filename: {file}\")\n",
    "  country = country_map[ccode]\n",
    "\n",
    "  # detect variable folder\n",
    "  if folder not in variable_map:\n",
    "    raise ValueError(f\"Unknown variable folder: {folder}\")\n",
    "  variable = variable_map[folder]\n",
    "\n",
    "  col_name = f\"{country}_{variable}\"\n",
    "\n",
    "  # load CSV\n",
    "  if path.suffix == \".csv\":\n",
    "    # skip metadata lines\n",
    "    with open(path) as f:\n",
    "      lines = f.read().splitlines()\n",
    "    header_index = next((i for i, line in enumerate(lines) if \"DATE\" in line or \"date\" in line), 0)\n",
    "    df = pd.read_csv(path, skiprows=header_index)\n",
    "\n",
    "  else:\n",
    "    # handles multiple sheets\n",
    "    xls = pd.ExcelFile(path)\n",
    "    df = None\n",
    "\n",
    "    for sheet in xls.sheet_names:\n",
    "      temp = pd.read_excel(path, sheet_name=sheet)\n",
    "\n",
    "      # find a date-like column\n",
    "      for col in temp.columns:\n",
    "        if temp[col].astype(str).str.match(r\"\\d{4}[-/]\\d{2}\").sum() > 3:\n",
    "          df = temp\n",
    "          date_col = col\n",
    "          break\n",
    "\n",
    "      if df is not None:\n",
    "        break\n",
    "\n",
    "    if df is None:\n",
    "      # fallback: load first sheet\n",
    "      df = pd.read_excel(path)\n",
    "      date_col = df.columns[0]\n",
    "\n",
    "  # ensure we have a date column\n",
    "  if date_col is None:\n",
    "    date_col = df.columns[0]\n",
    "\n",
    "  # parse dates\n",
    "  df[date_col] = smart_parse_dates(df[date_col])\n",
    "  df = df.dropna(subset=[date_col])\n",
    "  df = df.set_index(date_col).sort_index()\n",
    "\n",
    "  # rename value column\n",
    "  value_cols = [c for c in df.columns if c != date_col]\n",
    "  df = df.rename(columns={value_cols[0]: col_name})\n",
    "\n",
    "  return df, country, variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12f646ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONALITY: Imports all datasets in 'dataset' into all_sereies\n",
    "from pathlib import Path\n",
    "\n",
    "base = Path(\"dataset\")\n",
    "all_series = []\n",
    "\n",
    "for folder in base.iterdir():        # e.g. dataset/3M, dataset/CPI\n",
    "  if folder.is_dir():\n",
    "    for file in folder.iterdir():    # <-- file declared here\n",
    "      if file.suffix in [\".csv\", \".xlsx\", \".xls\"]:\n",
    "        df, country, variable = load_series_auto(file)\n",
    "        all_series.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd30cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONALITY: Turns all_series into a DataFrame\n",
    "from functools import reduce\n",
    "\n",
    "data = reduce(lambda left, right: left.join(right, how=\"outer\"), all_series)\n",
    "data = data.sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44793cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2052 entries, 1854-12-01 to 2025-11-01\n",
      "Data columns (total 35 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   ch_cpi  388 non-null    float64\n",
      " 1   eu_cpi  358 non-null    float64\n",
      " 2   jp_cpi  797 non-null    float64\n",
      " 3   kr_cpi  767 non-null    float64\n",
      " 4   uk_cpi  843 non-null    float64\n",
      " 5   us_cpi  945 non-null    float64\n",
      " 6   ch_exp  405 non-null    float64\n",
      " 7   eu_exp  400 non-null    float64\n",
      " 8   kr_exp  825 non-null    float64\n",
      " 9   uk_exp  849 non-null    float64\n",
      " 10  us_exp  314 non-null    float64\n",
      " 11  ch_gdp  127 non-null    float64\n",
      " 12  eu_gdp  122 non-null    float64\n",
      " 13  jp_gdp  831 non-null    float64\n",
      " 14  kr_gdp  255 non-null    float64\n",
      " 15  uk_gdp  279 non-null    float64\n",
      " 16  us_gdp  314 non-null    float64\n",
      " 17  ch_imp  405 non-null    float64\n",
      " 18  eu_imp  400 non-null    float64\n",
      " 19  jp_imp  813 non-null    float64\n",
      " 20  kr_imp  825 non-null    float64\n",
      " 21  uk_imp  825 non-null    float64\n",
      " 22  us_imp  314 non-null    float64\n",
      " 23  us_rec  2051 non-null   float64\n",
      " 24  eu_10y  670 non-null    float64\n",
      " 25  jp_10y  442 non-null    float64\n",
      " 26  kr_10y  301 non-null    float64\n",
      " 27  uk_10y  790 non-null    float64\n",
      " 28  us_10y  872 non-null    float64\n",
      " 29  ch_3m   339 non-null    float64\n",
      " 30  eu_3m   418 non-null    float64\n",
      " 31  jp_3m   515 non-null    float64\n",
      " 32  kr_3m   339 non-null    float64\n",
      " 33  uk_3m   478 non-null    float64\n",
      " 34  us_3m   1103 non-null   float64\n",
      "dtypes: float64(35)\n",
      "memory usage: 577.1 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67b1c4b",
   "metadata": {},
   "source": [
    "# 2.Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f260316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data shape: (431, 29)\n",
      "Date range: 1990-01 to 2025-11\n",
      "Recession rate: 8.4%\n"
     ]
    }
   ],
   "source": [
    "# FUNCTIONALITY: Cleans data by filtering dates and handling nulls\n",
    "data = data.loc[\"1990-01-01\":]\n",
    "\n",
    "# remove CPI columns (avoid inflation skewing)\n",
    "cpi_cols = [c for c in data.columns if 'cpi' in c]\n",
    "data = data.drop(columns=cpi_cols)\n",
    "\n",
    "# forward-fill quarterly data to monthly\n",
    "data = data.resample('MS').first()\n",
    "data = data.ffill().bfill().dropna()\n",
    "\n",
    "print(f\"Cleaned data shape: {data.shape}\")\n",
    "print(f\"Date range: {data.index.min().strftime('%Y-%m')} to {data.index.max().strftime('%Y-%m')}\")\n",
    "print(f\"Recession rate: {data['us_rec'].mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc5111e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (416, 24)\n",
      "Target shape: (416,)\n"
     ]
    }
   ],
   "source": [
    "# FUNCTIONALITY: Creates features for recession prediction\n",
    "import pandas as pd\n",
    "\n",
    "features = pd.DataFrame(index=data.index)\n",
    "\n",
    "# yield curve spreads (10Y - 3M) - key recession predictor\n",
    "features['us_yield_spread'] = data['us_10y'] - data['us_3m']\n",
    "features['uk_yield_spread'] = data['uk_10y'] - data['uk_3m']\n",
    "features['eu_yield_spread'] = data['eu_10y'] - data['eu_3m']\n",
    "features['jp_yield_spread'] = data['jp_10y'] - data['jp_3m']\n",
    "\n",
    "# interest rate levels\n",
    "for col in ['us_3m', 'us_10y', 'uk_3m', 'eu_3m', 'jp_3m']:\n",
    "  features[col] = data[col] \n",
    "\n",
    "\n",
    "# GDP growth rates (quarter-over-quarter)\n",
    "for col in [c for c in data.columns if 'gdp' in c]:\n",
    "  features[f'{col}_growth'] = data[col].pct_change(periods=3) * 100\n",
    "\n",
    "# trade balance\n",
    "features['us_trade_balance'] = data['us_exp'] - data['us_imp']\n",
    "\n",
    "# lagged features (to predict ahead)\n",
    "for lag in [3, 6, 12]:\n",
    "  features[f'us_yield_spread_lag{lag}'] = features['us_yield_spread'].shift(lag)\n",
    "  features[f'us_gdp_growth_lag{lag}'] = features['us_gdp_growth'].shift(lag)\n",
    "\n",
    "# rolling stats\n",
    "features['us_yield_spread_12m_avg'] = features['us_yield_spread'].rolling(12).mean()\n",
    "features['us_yield_spread_12m_min'] = features['us_yield_spread'].rolling(12).min()\n",
    "\n",
    "# clean and set target\n",
    "features = features.dropna()\n",
    "target = data.loc[features.index, 'us_rec']\n",
    "\n",
    "print(f\"Features shape: {features.shape}\")\n",
    "print(f\"Target shape: {target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5b59c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 297 obs, Test: 119 obs\n",
      "Train recessions: 26, Test recessions: 2\n",
      "\n",
      "AUC-ROC: 0.983\n",
      "F1 Score: 0.154\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.81      0.90       117\n",
      "         1.0       0.08      1.00      0.15         2\n",
      "\n",
      "    accuracy                           0.82       119\n",
      "   macro avg       0.54      0.91      0.53       119\n",
      "weighted avg       0.98      0.82      0.88       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FUNCTIONALITY: Trains logistic regression (binary classification)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, f1_score, classification_report\n",
    "\n",
    "# temporal train/test split\n",
    "split_date = '2015-12-31'\n",
    "X_train = features[features.index <= split_date]\n",
    "X_test = features[features.index > split_date]\n",
    "y_train = target[target.index <= split_date]\n",
    "y_test = target[target.index > split_date]\n",
    "\n",
    "print(f\"Train: {len(X_train)} obs, Test: {len(X_test)} obs\")\n",
    "print(f\"Train recessions: {int(y_train.sum())}, Test recessions: {int(y_test.sum())}\")\n",
    "\n",
    "# scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# train logistic regression\n",
    "# changed weight class to make it less aggressive (needs stronger evidence for recessions)\n",
    "model = LogisticRegression(class_weight={0: 1, 1: 5}, max_iter=1000, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# evaluate\n",
    "y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# adjust threshold (default is 0.5)\n",
    "threshold = 0.7  # <-- change this value\n",
    "y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "print(f\"\\nAUC-ROC: {roc_auc_score(y_test, y_prob):.3f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred, zero_division=0):.3f}\")\n",
    "print(f\"\\n{classification_report(y_test, y_pred, zero_division=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dcc757c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest data: November 2025\n",
      "Current recession probability: 12.8%\n",
      "\n",
      "Key indicators:\n",
      "  US Yield Spread: 0.31%\n",
      "  US GDP Growth:   0.0%\n"
     ]
    }
   ],
   "source": [
    "# FUNCTIONALITY: Gets current recession probability\n",
    "X_all_scaled = scaler.fit_transform(features)\n",
    "model.fit(X_all_scaled, target)\n",
    "\n",
    "# current probability\n",
    "current_prob = model.predict_proba(X_all_scaled[-1:])[:, 1][0]\n",
    "latest_date = features.index[-1].strftime('%B %Y')\n",
    "\n",
    "print(f\"Latest data: {latest_date}\")\n",
    "print(f\"Current recession probability: {current_prob*100:.1f}%\")\n",
    "print(f\"\\nKey indicators:\")\n",
    "print(f\"  US Yield Spread: {features['us_yield_spread'].iloc[-1]:.2f}%\")\n",
    "print(f\"  US GDP Growth:   {features['us_gdp_growth'].iloc[-1]:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "284174ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recession probability (last 12 months):\n",
      "  2024-12:   5.7% █\n",
      "  2025-01:  16.7% ███\n",
      "  2025-02:  14.8% ██\n",
      "  2025-03:  11.1% ██\n",
      "  2025-04:  10.0% ██\n",
      "  2025-05:   9.9% █\n",
      "  2025-06:   8.8% █\n",
      "  2025-07:  16.7% ███\n",
      "  2025-08:  18.1% ███\n",
      "  2025-09:  14.8% ██\n",
      "  2025-10:  15.2% ███\n",
      "  2025-11:  12.8% ██\n"
     ]
    }
   ],
   "source": [
    "# FUNCTIONALITY: Shows probability trend\n",
    "all_probs = model.predict_proba(X_all_scaled)[:, 1]\n",
    "\n",
    "print(\"Recession probability (last 12 months):\")\n",
    "for i in range(-12, 0):\n",
    "  date = features.index[i].strftime('%Y-%m')\n",
    "  prob = all_probs[i]\n",
    "  bar = '█' * int(prob * 20)\n",
    "  rec = ' ← RECESSION' if target.iloc[i] == 1 else ''\n",
    "  print(f\"  {date}: {prob*100:5.1f}% {bar}{rec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acbd186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONALITY: Trains random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# train random forest\n",
    "rf_model = RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# evaluate\n",
    "rf_prob = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "rf_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test, rf_prob):.3f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, rf_pred, zero_division=0):.3f}\")\n",
    "print(f\"\\n{classification_report(y_test, rf_pred, zero_division=0)}\")\n",
    "\n",
    "# feature importance\n",
    "importance = pd.Series(rf_model.feature_importances_, index=features.columns)\n",
    "print(\"\\nTop 10 important features:\")\n",
    "for feat, imp in importance.sort_values(ascending=False).head(10).items():\n",
    "  print(f\"  {feat}: {imp:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
